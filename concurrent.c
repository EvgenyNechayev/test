/*
 * concurrent.c
 *	  code to handle changes that took place while new table was being created
 */

#include "pg_squeeze.h"

#include "replication/decode.h"
#include "utils/rel.h"

static void update_indexes(Relation heap, HeapTuple tuple, Oid *indexes,
						   int nindexes);

void
decode_concurrent_changes(LogicalDecodingContext *ctx, XLogRecPtr *startptr,
						  XLogRecPtr end_of_wal, ResourceOwner resowner)
{
	ResourceOwner	resowner_old;

	/*
	 * Invalidate the "present" cache before moving to "(recent) history".
	 *
	 * The cache entry of the transient relation is not affected (because it
	 * was created by the current transaction), but the tuple descriptor
	 * shouldn't change anymore (as opposed to index info, which we change at
	 * some point, but that shouldn't break the logical decoding).
	 *
	 * Note: The logical changes generated by the transient relation are
	 * eventually ignored, but tuple creation can't be avoided. Thus we ought
	 * to care about using the correct tuple descriptor.
	 */
	InvalidateSystemCaches();

	resowner_old = CurrentResourceOwner;
	CurrentResourceOwner = resowner;

	PG_TRY();
	{
		while ((*startptr != InvalidXLogRecPtr && *startptr < end_of_wal) ||
			   (ctx->reader->EndRecPtr != InvalidXLogRecPtr &&
				ctx->reader->EndRecPtr < end_of_wal))
		{
			XLogRecord *record;
			char	   *errm = NULL;

			record = XLogReadRecord(ctx->reader, *startptr, &errm);
			if (errm)
				elog(ERROR, "%s", errm);

			*startptr = InvalidXLogRecPtr;

			if (record != NULL)
				LogicalDecodingProcessRecord(ctx, ctx->reader);

			CHECK_FOR_INTERRUPTS();
		}
		InvalidateSystemCaches();
		CurrentResourceOwner = resowner_old;
	}
	PG_CATCH();
	{
		InvalidateSystemCaches();
		CurrentResourceOwner = resowner_old;
		PG_RE_THROW();
	}
	PG_END_TRY();
}


/*
 * Process changes that happened during the initial load.
 *
 * Scan key is passed by caller, so it does not have to be constructed
 * multiple times.
 *
 * Index list is passed explicitly as the relation cache entry is not supposed
 * to reflect changes of our transaction (unless we want to reload it, which
 * seems an overkill).
 *
 * For the same reason, ident_index is passed separate. (XXX The PoC does not
 * create constraints, so relation->rd_replidindex field would be empty
 * anyway. But this approach might change in the future.)
 */
void
process_concurrent_changes(DecodingOutputState *s, Relation relation,
						   ScanKey key, int nkeys, Oid *indexes, int nindexes,
						   Oid ident_index)
{
	TupleTableSlot	*slot_data, *slot_metadata;
	HeapTuple tup_old = NULL;
	BulkInsertState bistate = NULL;

	slot_metadata = MakeTupleTableSlot();
	ExecSetSlotDescriptor(slot_metadata, s->metadata.tupdesc);

	slot_data = MakeTupleTableSlot();
	ExecSetSlotDescriptor(slot_data, s->data.tupdesc);

	while (tuplestore_gettupleslot(s->metadata.tupstore, true, false,
								   slot_metadata))
	{
		HeapTuple tup_meta, tup, tup_exist;
		Datum	kind_value[1];
		bool	kind_isnull[1];
		char	change_kind;

		if (!tuplestore_gettupleslot(s->data.tupstore, true, false,
									 slot_data))
			elog(ERROR, "The data and metadata slots do not match.");

		/* Find out of what kind current change is. */
		tup_meta = ExecCopySlotTuple(slot_metadata);
		heap_deform_tuple(tup_meta, slot_metadata->tts_tupleDescriptor,
						  kind_value, kind_isnull);
		Assert(!kind_isnull[0]);
		change_kind = DatumGetChar(kind_value[0]);

		/*
		 * Do not keep buffer pinned for insert if the current change is
		 * something else.
		 */
		if (change_kind != PG_SQUEEZE_CHANGE_INSERT && bistate != NULL)
		{
			FreeBulkInsertState(bistate);
			bistate = NULL;
		}

		tup = ExecCopySlotTuple(slot_data);
		if (change_kind == PG_SQUEEZE_CHANGE_UPDATE_OLD)
		{
			Assert(tup_old == NULL);
			tup_old = tup;
		}
		else if (change_kind == PG_SQUEEZE_CHANGE_INSERT)
		{
			Assert(tup_old == NULL);

			/*
			 * If the next change will also be INSERT, we'll try to use the
			 * same buffer.
			 */
			if (bistate == NULL)
				bistate = GetBulkInsertState();

			heap_insert(relation, tup, GetCurrentCommandId(true), 0, bistate);
			update_indexes(relation, tup, indexes, nindexes);
			pfree(tup);
		}
		else if (change_kind == PG_SQUEEZE_CHANGE_UPDATE_NEW ||
				 change_kind == PG_SQUEEZE_CHANGE_DELETE)
		{
			HeapTuple	tup_key;
			IndexScanDesc	scan;
			int i;
			ItemPointerData	ctid;
			Relation	index;

			if (change_kind == PG_SQUEEZE_CHANGE_UPDATE_NEW)
			{
				tup_key = tup_old != NULL ? tup_old : tup;
			}
			else
			{
				Assert(tup_old == NULL);
				tup_key = tup;
			}

			/* No lock, the parent relation is not yet visible to others. */
			index = index_open(ident_index, NoLock);

			/*
			 * Find the tuple to be updated or deleted.
			 *
			 * XXX Not sure we need PushActiveSnapshot() - as the table is not
			 * visible to other transactions, the xmin, xmax, xip, etc. fields
			 * of the snapshot are not important, and CurrentSnapshot->curcid
			 * should stay consistent with CommandCounterIncrement() even if
			 * GetSnapshotData() gets called anytime.
			 *
			 * XXX As no other transactions are engaged, SnapshotSelf might
			 * seem to prevent us from wasting values of the command counter
			 * (as we do not update catalog here, cache invalidation is not
			 * the reason to increment the counter). However, heap_update()
			 * does require CommandCounterIncrement().
			 */
			scan = index_beginscan(relation, index, GetTransactionSnapshot(),
								   nkeys, 0);

			index_rescan(scan, key, nkeys, NULL, 0);

			/* Use the incoming tuple to finalize the scan key. */
			for (i = 0; i < scan->numberOfKeys; i++)
			{
				ScanKey	entry;
				bool	isnull;

				entry = &scan->keyData[i];
				entry->sk_argument = heap_getattr(tup_key,
												  entry->sk_attno,
												  relation->rd_att,
												  &isnull);
				Assert(!isnull);
			}
			tup_exist = index_getnext(scan, ForwardScanDirection);
			if (tup_exist == NULL)
				elog(ERROR, "Failed to find target tuple");
			ItemPointerCopy(&tup_exist->t_self, &ctid);
			index_endscan(scan);
			index_close(index, NoLock);

			if (change_kind == PG_SQUEEZE_CHANGE_UPDATE_NEW)
			{
				simple_heap_update(relation, &ctid, tup);
				if (!HeapTupleIsHeapOnly(tup))
					update_indexes(relation, tup, indexes, nindexes);
			}
			else
				simple_heap_delete(relation, &ctid);

			if (tup_old != NULL)
			{
				pfree(tup_old);
				tup_old = NULL;
			}

			pfree(tup);
		}
		else
			elog(ERROR, "Unrecognized kind of change: %d", change_kind);

		/* If there's any change, make it visible to the next iteration. */
		if (change_kind != PG_SQUEEZE_CHANGE_UPDATE_OLD)
			CommandCounterIncrement();
		pfree(tup_meta);
	}

	/* Cleanup. */
	if (bistate != NULL)
		FreeBulkInsertState(bistate);

	if (tuplestore_gettupleslot(s->data.tupstore, true, false,
								 slot_data))
		elog(ERROR, "The data and metadata slots do not match.");

	ExecDropSingleTupleTableSlot(slot_data);
	ExecDropSingleTupleTableSlot(slot_metadata);
}

/* Insert ctid into all indexes of relation. */
static void
update_indexes(Relation heap, HeapTuple tuple, Oid *indexes, int nindexes)
{
	int i;
	Datum	*values_heap;
	bool	*isnull_heap;
	int	natts_heap;
	ItemPointerData	ctid;

	/*
	 * TODO Find out if FormIndexDatum() works with MinimalTuple. Repeated
	 * retrieval from slot might not require deforming of the whole heap
	 * tuple.
	 */
	natts_heap = heap->rd_att->natts;
	values_heap = (Datum *) palloc(natts_heap * sizeof(Datum));
	isnull_heap = (bool *) palloc(natts_heap * sizeof(bool));
	heap_deform_tuple(tuple, heap->rd_att, values_heap, isnull_heap);
	ItemPointerCopy(&tuple->t_self, &ctid);

	for (i = 0; i < nindexes; i++)
	{
		Relation rel_ind;
		Datum *values;
		bool *isnull;
		Form_pg_index	ind_form;
		int	indnatts;
		int	j;

		rel_ind = index_open(indexes[i], RowExclusiveLock);
		ind_form = rel_ind->rd_index;
		indnatts = ind_form->indnatts;
		values = (Datum *) palloc(indnatts * sizeof(Datum));
		isnull = (bool *) palloc(indnatts * sizeof(bool));
		for (j = 0; j < indnatts; j++)
		{
			AttrNumber	attno_heap;

			attno_heap = ind_form->indkey.values[j] - 1;
			values[j] = values_heap[attno_heap];
			isnull[j] = isnull_heap[attno_heap];
		}
		index_insert(rel_ind, values, isnull, &ctid, heap,
					 ind_form->indisunique);
		pfree(values);
		pfree(isnull);
		index_close(rel_ind, RowExclusiveLock);
	}
	pfree(values_heap);
	pfree(isnull_heap);
}
